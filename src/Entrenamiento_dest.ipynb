{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO Y EVALUACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 00:26:50.437106: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-24 00:26:50.502213: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-24 00:26:50.503915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 00:26:51.585218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections as cols\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Cargar los datos preprocesados\n",
    "file_path = 'databases/Base de datos para desarrollo v2_dest(preprocesada).csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        __temperatura   __pulso     __pas     __pad   __sat02\n",
      "0            0.229959 -0.141229 -0.090837 -0.514129  0.166636\n",
      "1           -4.667926 -3.667914 -2.134067 -2.059868 -6.671051\n",
      "2           -4.667926 -1.223280  0.405649  0.495334  0.236409\n",
      "3            0.229959  1.902645  1.379525  1.094702  0.306181\n",
      "4            0.203121  0.980898 -0.530036  0.179877  0.236409\n",
      "...               ...       ...       ...       ...       ...\n",
      "189077       0.109189  0.099227 -0.186315 -0.514129  0.306181\n",
      "189078       0.068933  0.540062 -0.186315 -0.514129  0.027092\n",
      "189079       0.082352 -0.702292  0.653892  0.810791  0.166636\n",
      "189080       0.162865 -0.501913  0.443840  0.400697  0.236409\n",
      "189081       0.229959 -1.062976  0.138310 -0.324855  0.306181\n",
      "\n",
      "[189082 rows x 5 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "189077    1\n",
      "189078    1\n",
      "189079    1\n",
      "189080    1\n",
      "189081    1\n",
      "Name: __destino, Length: 189082, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2 Separar las características de entrada y de salida (objetivo)\n",
    "input = df.drop(columns=['__destino'])\n",
    "output = df['__destino']\n",
    "\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir la salida a categorías\n",
    "output = to_categorical(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Dividir los datos en conjuntos de entrenamiento 80% y prueba 20% \n",
    "input_train, input_test, output_train, output_test = train_test_split(input, output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Construir el modelo dela red neuronal (Perceptron multicapa)\n",
    "def MLP_NN():\n",
    "    NumNeurons = 7\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_train.shape[1]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output.shape[1], activation='softmax'))  # Usar 'softmax' para clasificación multiclase\n",
    "\n",
    "    #opt =  keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 00:26:53.180655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-24 00:26:53.181951: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3782/3782 [==============================] - 6s 1ms/step - loss: 0.6540 - accuracy: 0.6076 - val_loss: 0.6273 - val_accuracy: 0.6373\n",
      "Epoch 2/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6339 - accuracy: 0.6319 - val_loss: 0.6226 - val_accuracy: 0.6365\n",
      "Epoch 3/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6304 - accuracy: 0.6340 - val_loss: 0.6203 - val_accuracy: 0.6414\n",
      "Epoch 4/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6283 - accuracy: 0.6372 - val_loss: 0.6192 - val_accuracy: 0.6410\n",
      "Epoch 5/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6272 - accuracy: 0.6389 - val_loss: 0.6182 - val_accuracy: 0.6450\n",
      "Epoch 6/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6261 - accuracy: 0.6383 - val_loss: 0.6171 - val_accuracy: 0.6444\n",
      "Epoch 7/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6255 - accuracy: 0.6395 - val_loss: 0.6166 - val_accuracy: 0.6464\n",
      "Epoch 8/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6262 - accuracy: 0.6391 - val_loss: 0.6160 - val_accuracy: 0.6449\n",
      "Epoch 9/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6251 - accuracy: 0.6393 - val_loss: 0.6148 - val_accuracy: 0.6485\n",
      "Epoch 10/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6247 - accuracy: 0.6404 - val_loss: 0.6150 - val_accuracy: 0.6441\n",
      "Epoch 11/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6243 - accuracy: 0.6399 - val_loss: 0.6152 - val_accuracy: 0.6464\n",
      "Epoch 12/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6247 - accuracy: 0.6395 - val_loss: 0.6161 - val_accuracy: 0.6473\n",
      "Epoch 13/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6244 - accuracy: 0.6400 - val_loss: 0.6154 - val_accuracy: 0.6469\n",
      "Epoch 14/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6246 - accuracy: 0.6406 - val_loss: 0.6145 - val_accuracy: 0.6463\n",
      "Epoch 15/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6235 - accuracy: 0.6402 - val_loss: 0.6155 - val_accuracy: 0.6464\n",
      "Epoch 16/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6233 - accuracy: 0.6418 - val_loss: 0.6137 - val_accuracy: 0.6483\n",
      "Epoch 17/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6233 - accuracy: 0.6421 - val_loss: 0.6131 - val_accuracy: 0.6484\n",
      "Epoch 18/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6231 - accuracy: 0.6416 - val_loss: 0.6124 - val_accuracy: 0.6469\n",
      "Epoch 19/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6234 - accuracy: 0.6402 - val_loss: 0.6134 - val_accuracy: 0.6479\n",
      "Epoch 20/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6231 - accuracy: 0.6403 - val_loss: 0.6146 - val_accuracy: 0.6496\n",
      "Epoch 21/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6229 - accuracy: 0.6408 - val_loss: 0.6135 - val_accuracy: 0.6463\n",
      "Epoch 22/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6232 - accuracy: 0.6411 - val_loss: 0.6130 - val_accuracy: 0.6502\n",
      "Epoch 23/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6234 - accuracy: 0.6403 - val_loss: 0.6135 - val_accuracy: 0.6492\n",
      "Epoch 24/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6233 - accuracy: 0.6417 - val_loss: 0.6116 - val_accuracy: 0.6498\n",
      "Epoch 25/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6227 - accuracy: 0.6427 - val_loss: 0.6141 - val_accuracy: 0.6469\n",
      "Epoch 26/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6232 - accuracy: 0.6414 - val_loss: 0.6160 - val_accuracy: 0.6445\n",
      "Epoch 27/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6236 - accuracy: 0.6398 - val_loss: 0.6141 - val_accuracy: 0.6485\n",
      "Epoch 28/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6227 - accuracy: 0.6414 - val_loss: 0.6148 - val_accuracy: 0.6509\n",
      "Epoch 29/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6227 - accuracy: 0.6411 - val_loss: 0.6123 - val_accuracy: 0.6478\n",
      "Epoch 30/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6226 - accuracy: 0.6417 - val_loss: 0.6133 - val_accuracy: 0.6474\n",
      "Epoch 31/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6218 - accuracy: 0.6420 - val_loss: 0.6143 - val_accuracy: 0.6473\n",
      "Epoch 32/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6233 - accuracy: 0.6413 - val_loss: 0.6121 - val_accuracy: 0.6477\n",
      "Epoch 33/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6228 - accuracy: 0.6413 - val_loss: 0.6135 - val_accuracy: 0.6465\n",
      "Epoch 34/500\n",
      "3782/3782 [==============================] - 5s 1ms/step - loss: 0.6227 - accuracy: 0.6409 - val_loss: 0.6122 - val_accuracy: 0.6495\n"
     ]
    }
   ],
   "source": [
    "#5 Entrenar el modelo\n",
    "n_epochs = 500\n",
    "#network = MLP_NN()\n",
    "#train = network.fit(input_train, output_train, epochs=n_epochs, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "network = MLP_NN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "train = network.fit(input_train, output_train, epochs=n_epochs, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182/1182 [==============================] - 1s 1ms/step - loss: 0.6117 - accuracy: 0.6492\n",
      "Precisión en el conjunto de prueba: 0.65\n"
     ]
    }
   ],
   "source": [
    "#6 Evaluar el modelo\n",
    "loss, accuracy = network.evaluate(input_test, output_test)\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182/1182 [==============================] - 1s 854us/step\n",
      "[[0.5465424  0.45345765]\n",
      " [0.5532324  0.44676748]\n",
      " [0.48811096 0.5118891 ]\n",
      " ...\n",
      " [0.3704701  0.6295299 ]\n",
      " [0.19076915 0.80923086]\n",
      " [0.48596475 0.5140352 ]]\n",
      "[0 0 1 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#7 Predicciones\n",
    "output_pred = network.predict(input_test)\n",
    "print(output_pred)\n",
    "output_pred_classes = np.argmax(output_pred, axis=1)\n",
    "print(output_pred_classes)\n",
    "output_test_classes = np.argmax(output_test, axis=1)\n",
    "print(output_test_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61     18942\n",
      "           1       0.62      0.75      0.68     18875\n",
      "\n",
      "    accuracy                           0.65     37817\n",
      "   macro avg       0.65      0.65      0.65     37817\n",
      "weighted avg       0.66      0.65      0.65     37817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8 Generar el reporte de clasificación\n",
    "print(classification_report(output_test_classes, output_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10487  8455]\n",
      " [ 4812 14063]]\n"
     ]
    }
   ],
   "source": [
    "#9 Matriz de confusión\n",
    "print(confusion_matrix(output_test_classes, output_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4728/4728 [==============================] - 5s 970us/step\n",
      "[[41980 33619]\n",
      " [19341 56325]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión con datos de entrenamiento\n",
    "output_train_pred = network.predict(input_train)\n",
    "output_train_pred_classes = np.argmax(output_train_pred, axis=1)\n",
    "output_train_classes = np.argmax(output_train, axis=1)\n",
    "print(confusion_matrix(output_train_classes, output_train_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
