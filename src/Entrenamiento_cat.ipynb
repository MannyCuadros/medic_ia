{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 12:41:11.725380: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-22 12:41:11.768802: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-22 12:41:11.769524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-22 12:41:12.528080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections as cols\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Cargar los datos preprocesados\n",
    "file_path = 'databases/Base de datos para desarrollo v2_cat(preprocesada).csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       __temperatura   __pulso     __pas     __pad   __sat02\n",
      "0           0.399555  3.522748 -2.084207 -1.004273 -2.136869\n",
      "1          -0.496330  3.291283  3.483932  2.135313 -7.096196\n",
      "2           0.175589  1.092363 -2.654174 -2.247026 -6.104331\n",
      "3          -2.512055  1.613159 -0.286619  1.612049 -2.632802\n",
      "4           0.399555  3.638481  1.028690  0.696336 -6.104331\n",
      "...              ...       ...       ...       ...       ...\n",
      "76805      -1.168238 -0.527894  0.897159 -0.284784 -0.153138\n",
      "76806      -0.272353  0.687298  0.195661 -1.069681 -1.145004\n",
      "76807      -0.272353 -0.007097 -0.461993 -0.677233  0.342795\n",
      "76808       0.399555 -0.180696 -0.330462  0.303888  0.838727\n",
      "76809       0.399555  0.108635 -1.470397 -0.808049  0.342795\n",
      "\n",
      "[76810 rows x 5 columns]\n",
      "0        3\n",
      "1        3\n",
      "2        3\n",
      "3        3\n",
      "4        3\n",
      "        ..\n",
      "76805    5\n",
      "76806    5\n",
      "76807    5\n",
      "76808    5\n",
      "76809    5\n",
      "Name: __categ_fin, Length: 76810, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2 Separar las características de entrada y de salida (objetivo)\n",
    "input = df.drop(columns=['__categ_fin'])\n",
    "output = df['__categ_fin']\n",
    "\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir la salida a categorías\n",
    "output = to_categorical(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Dividir los datos en conjuntos de entrenamiento 80% y prueba 20% \n",
    "input_train, input_test, output_train, output_test = train_test_split(input, output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Construir el modelo dela red neuronal (Perceptron multicapa)\n",
    "def MLP_NN():\n",
    "    NumNeurons = 7\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_train.shape[1]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output.shape[1], activation='softmax'))  # Usar 'softmax' para clasificación multiclase\n",
    "\n",
    "    #opt =  keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 12:41:13.838296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-22 12:41:13.841048: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 [==============================] - 3s 2ms/step - loss: 1.1052 - accuracy: 0.4371 - val_loss: 1.0051 - val_accuracy: 0.4924\n",
      "Epoch 2/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 1.0202 - accuracy: 0.4777 - val_loss: 1.0009 - val_accuracy: 0.4941\n",
      "Epoch 3/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 1.0101 - accuracy: 0.4862 - val_loss: 0.9936 - val_accuracy: 0.5019\n",
      "Epoch 4/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 1.0055 - accuracy: 0.4895 - val_loss: 0.9930 - val_accuracy: 0.5033\n",
      "Epoch 5/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 1.0016 - accuracy: 0.4929 - val_loss: 0.9906 - val_accuracy: 0.5050\n",
      "Epoch 6/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 1.0009 - accuracy: 0.4933 - val_loss: 0.9894 - val_accuracy: 0.5081\n",
      "Epoch 7/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9976 - accuracy: 0.4956 - val_loss: 0.9878 - val_accuracy: 0.5111\n",
      "Epoch 8/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9964 - accuracy: 0.4967 - val_loss: 0.9865 - val_accuracy: 0.5123\n",
      "Epoch 9/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9960 - accuracy: 0.4999 - val_loss: 0.9879 - val_accuracy: 0.5059\n",
      "Epoch 10/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9936 - accuracy: 0.4995 - val_loss: 0.9846 - val_accuracy: 0.5094\n",
      "Epoch 11/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9928 - accuracy: 0.5033 - val_loss: 0.9857 - val_accuracy: 0.5136\n",
      "Epoch 12/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9928 - accuracy: 0.5035 - val_loss: 0.9850 - val_accuracy: 0.5131\n",
      "Epoch 13/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9922 - accuracy: 0.5024 - val_loss: 0.9836 - val_accuracy: 0.5126\n",
      "Epoch 14/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9924 - accuracy: 0.5019 - val_loss: 0.9841 - val_accuracy: 0.5102\n",
      "Epoch 15/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9913 - accuracy: 0.5028 - val_loss: 0.9844 - val_accuracy: 0.5103\n",
      "Epoch 16/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9912 - accuracy: 0.5043 - val_loss: 0.9862 - val_accuracy: 0.5089\n",
      "Epoch 17/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9908 - accuracy: 0.5038 - val_loss: 0.9856 - val_accuracy: 0.5076\n",
      "Epoch 18/500\n",
      "1537/1537 [==============================] - 3s 2ms/step - loss: 0.9900 - accuracy: 0.5062 - val_loss: 0.9856 - val_accuracy: 0.5100\n",
      "Epoch 19/500\n",
      "1537/1537 [==============================] - 2s 2ms/step - loss: 0.9918 - accuracy: 0.5053 - val_loss: 0.9852 - val_accuracy: 0.5080\n",
      "Epoch 20/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9906 - accuracy: 0.5047 - val_loss: 0.9844 - val_accuracy: 0.5090\n",
      "Epoch 21/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9918 - accuracy: 0.5053 - val_loss: 0.9847 - val_accuracy: 0.5107\n",
      "Epoch 22/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9901 - accuracy: 0.5045 - val_loss: 0.9856 - val_accuracy: 0.5098\n",
      "Epoch 23/500\n",
      "1537/1537 [==============================] - 2s 1ms/step - loss: 0.9902 - accuracy: 0.5042 - val_loss: 0.9844 - val_accuracy: 0.5094\n"
     ]
    }
   ],
   "source": [
    "#5 Entrenar el modelo\n",
    "n_epochs = 500\n",
    "#network = MLP_NN()\n",
    "#train = network.fit(input_train, output_train, epochs=n_epochs, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "network = MLP_NN()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "train = network.fit(input_train, output_train, epochs=n_epochs, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 [==============================] - 0s 933us/step - loss: 0.9820 - accuracy: 0.5145\n",
      "Precisión en el conjunto de prueba: 0.51\n"
     ]
    }
   ],
   "source": [
    "#6 Evaluar el modelo\n",
    "loss, accuracy = network.evaluate(input_test, output_test)\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 [==============================] - 0s 773us/step\n",
      "[[7.8088578e-07 7.4947451e-07 7.3677489e-07 1.4743207e-01 3.3981586e-01\n",
      "  5.1274985e-01]\n",
      " [3.4163497e-07 3.2701726e-07 3.1428257e-07 1.5569378e-01 3.4785512e-01\n",
      "  4.9645019e-01]\n",
      " [4.5422078e-07 4.1917752e-07 5.4185676e-07 1.9074339e-01 3.7677023e-01\n",
      "  4.3248495e-01]\n",
      " ...\n",
      " [6.4918152e-07 6.4173770e-07 6.6737090e-07 1.5956125e-01 3.4459558e-01\n",
      "  4.9584118e-01]\n",
      " [8.6817028e-07 8.5545508e-07 8.3568000e-07 1.5719815e-01 3.4478357e-01\n",
      "  4.9801567e-01]\n",
      " [1.0607201e-07 8.0907704e-08 8.2937817e-08 2.2693910e-01 4.4193897e-01\n",
      "  3.3112174e-01]]\n",
      "[5 5 5 ... 5 5 4]\n",
      "[5 4 5 ... 4 5 3]\n"
     ]
    }
   ],
   "source": [
    "#7 Predicciones\n",
    "output_pred = network.predict(input_test)\n",
    "print(output_pred)\n",
    "output_pred_classes = np.argmax(output_pred, axis=1)\n",
    "print(output_pred_classes)\n",
    "output_test_classes = np.argmax(output_test, axis=1)\n",
    "print(output_test_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.62      0.30      0.40      3735\n",
      "           4       0.48      0.43      0.45      5771\n",
      "           5       0.51      0.74      0.61      5856\n",
      "\n",
      "    accuracy                           0.51     15362\n",
      "   macro avg       0.54      0.49      0.49     15362\n",
      "weighted avg       0.53      0.51      0.50     15362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8 Generar el reporte de clasificación\n",
    "print(classification_report(output_test_classes, output_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1109 1268 1358]\n",
      " [ 583 2467 2721]\n",
      " [  86 1443 4327]]\n"
     ]
    }
   ],
   "source": [
    "#9 Matriz de confusión\n",
    "print(confusion_matrix(output_test_classes, output_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1921/1921 [==============================] - 2s 778us/step\n",
      "[[ 4530  5250  5274]\n",
      " [ 2141  9711 10948]\n",
      " [  376  5905 17313]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión con datos de entrenamiento\n",
    "output_train_pred = network.predict(input_train)\n",
    "output_train_pred_classes = np.argmax(output_train_pred, axis=1)\n",
    "output_train_classes = np.argmax(output_train, axis=1)\n",
    "print(confusion_matrix(output_train_classes, output_train_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
