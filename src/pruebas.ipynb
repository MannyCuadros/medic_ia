{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        var001       var002      var003  month  year     __sexo  __hgt  \\\n",
      "0       168692  U0004802741   4/11/2023      4  2023  Masculino    NaN   \n",
      "1       214287  U0005119913   11/5/2023     11  2023  Masculino    NaN   \n",
      "2       113755  U0004427396   8/13/2022      8  2022  Masculino    NaN   \n",
      "3       202840  U0005038530   9/16/2023      9  2023  Masculino    NaN   \n",
      "4        31544  U0003873327    7/6/2021      7  2021  Masculino    NaN   \n",
      "...        ...          ...         ...    ...   ...        ...    ...   \n",
      "103156  137998  U0004600580  11/26/2022     11  2022   Femenino    NaN   \n",
      "103157   50108  U0003998985  10/21/2021     10  2021   Femenino  101.0   \n",
      "103158   98326  U0004327713    6/3/2022      6  2022  Masculino    NaN   \n",
      "103159  187747  U0004932755    7/1/2023      7  2023  Masculino    NaN   \n",
      "103160  108243  U0004392833   7/20/2022      7  2022   Femenino    NaN   \n",
      "\n",
      "        __temperatura  __pulso  __pas  __pad  __fres  __sat02  __peso  \\\n",
      "0           36.299999     81.0    NaN    NaN     NaN     99.0    42.0   \n",
      "1           36.400002    105.0  185.0   96.0     NaN     99.0     NaN   \n",
      "2           36.200001    101.0    NaN    NaN     NaN     99.0    32.0   \n",
      "3           36.400002    106.0  125.0   99.0     NaN     99.0     NaN   \n",
      "4           36.500000     57.0  118.0   66.0     NaN    100.0     NaN   \n",
      "...               ...      ...    ...    ...     ...      ...     ...   \n",
      "103156      36.299999     74.0  152.0   97.0     NaN     98.0     NaN   \n",
      "103157      36.500000     60.0  143.0   78.0     NaN     98.0     NaN   \n",
      "103158      36.299999     77.0  163.0   77.0     NaN    100.0     NaN   \n",
      "103159      36.400002    112.0  143.0   83.0     NaN     98.0     NaN   \n",
      "103160      36.000000     82.0  167.0   90.0     NaN     98.0     NaN   \n",
      "\n",
      "        __outcome_1  __destino  __outcome_2  __outcome_3 __categorizacion  \n",
      "0               0.0  Domicilio          0.0          0.0               C4  \n",
      "1               0.0  Domicilio          0.0          0.0               C4  \n",
      "2               0.0  Domicilio          0.0          0.0               C3  \n",
      "3               0.0  Domicilio          0.0          0.0               C4  \n",
      "4               0.0  Domicilio          0.0          0.0               C5  \n",
      "...             ...        ...          ...          ...              ...  \n",
      "103156          0.0  Domicilio          0.0          0.0               C3  \n",
      "103157          0.0  Domicilio          0.0          0.0               C2  \n",
      "103158          0.0  Domicilio          0.0          0.0               C4  \n",
      "103159          0.0  Domicilio          0.0          0.0               C4  \n",
      "103160          0.0  Domicilio          0.0          0.0               C3  \n",
      "\n",
      "[103161 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos en un DataFrame\n",
    "data = pd.read_csv('databases/Base de datos HACQ.csv', sep=',')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month     __sexo  __hgt  __temperatura  __pulso  __pas  __pad  __fres  \\\n",
      "0           4  Masculino    NaN      36.299999     81.0    NaN    NaN     NaN   \n",
      "1          11  Masculino    NaN      36.400002    105.0  185.0   96.0     NaN   \n",
      "2           8  Masculino    NaN      36.200001    101.0    NaN    NaN     NaN   \n",
      "3           9  Masculino    NaN      36.400002    106.0  125.0   99.0     NaN   \n",
      "4           7  Masculino    NaN      36.500000     57.0  118.0   66.0     NaN   \n",
      "...       ...        ...    ...            ...      ...    ...    ...     ...   \n",
      "103156     11   Femenino    NaN      36.299999     74.0  152.0   97.0     NaN   \n",
      "103157     10   Femenino  101.0      36.500000     60.0  143.0   78.0     NaN   \n",
      "103158      6  Masculino    NaN      36.299999     77.0  163.0   77.0     NaN   \n",
      "103159      7  Masculino    NaN      36.400002    112.0  143.0   83.0     NaN   \n",
      "103160      7   Femenino    NaN      36.000000     82.0  167.0   90.0     NaN   \n",
      "\n",
      "        __sat02  __peso __categorizacion  \n",
      "0          99.0    42.0               C4  \n",
      "1          99.0     NaN               C4  \n",
      "2          99.0    32.0               C3  \n",
      "3          99.0     NaN               C4  \n",
      "4         100.0     NaN               C5  \n",
      "...         ...     ...              ...  \n",
      "103156     98.0     NaN               C3  \n",
      "103157     98.0     NaN               C2  \n",
      "103158    100.0     NaN               C4  \n",
      "103159     98.0     NaN               C4  \n",
      "103160     98.0     NaN               C3  \n",
      "\n",
      "[103161 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos las columnas no necesarias\n",
    "columns_to_drop = [\"var001\", \"var002\", \"var003\", \"year\", \"__outcome_1\", \"__outcome_2\", \"__destino\", \"__outcome_3\"]\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month     __sexo  __temperatura  __pulso  __pas  __pad  __sat02  \\\n",
      "0           4  Masculino      36.299999     81.0    NaN    NaN     99.0   \n",
      "1          11  Masculino      36.400002    105.0  185.0   96.0     99.0   \n",
      "2           8  Masculino      36.200001    101.0    NaN    NaN     99.0   \n",
      "3           9  Masculino      36.400002    106.0  125.0   99.0     99.0   \n",
      "4           7  Masculino      36.500000     57.0  118.0   66.0    100.0   \n",
      "...       ...        ...            ...      ...    ...    ...      ...   \n",
      "103156     11   Femenino      36.299999     74.0  152.0   97.0     98.0   \n",
      "103157     10   Femenino      36.500000     60.0  143.0   78.0     98.0   \n",
      "103158      6  Masculino      36.299999     77.0  163.0   77.0    100.0   \n",
      "103159      7  Masculino      36.400002    112.0  143.0   83.0     98.0   \n",
      "103160      7   Femenino      36.000000     82.0  167.0   90.0     98.0   \n",
      "\n",
      "       __categorizacion  \n",
      "0                    C4  \n",
      "1                    C4  \n",
      "2                    C3  \n",
      "3                    C4  \n",
      "4                    C5  \n",
      "...                 ...  \n",
      "103156               C3  \n",
      "103157               C2  \n",
      "103158               C4  \n",
      "103159               C4  \n",
      "103160               C3  \n",
      "\n",
      "[103161 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Manejamos los datos faltantes\n",
    "# Podemos optar por eliminar las columnas con muchos datos vacíos\n",
    "data = data.drop(columns=[\"__hgt\", \"__fres\", \"__peso\"])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  __sexo  __temperatura  __pulso  __pas  __pad  __sat02  \\\n",
      "0           4       1      36.299999     81.0    NaN    NaN     99.0   \n",
      "1          11       1      36.400002    105.0  185.0   96.0     99.0   \n",
      "2           8       1      36.200001    101.0    NaN    NaN     99.0   \n",
      "3           9       1      36.400002    106.0  125.0   99.0     99.0   \n",
      "4           7       1      36.500000     57.0  118.0   66.0    100.0   \n",
      "...       ...     ...            ...      ...    ...    ...      ...   \n",
      "103156     11       0      36.299999     74.0  152.0   97.0     98.0   \n",
      "103157     10       0      36.500000     60.0  143.0   78.0     98.0   \n",
      "103158      6       1      36.299999     77.0  163.0   77.0    100.0   \n",
      "103159      7       1      36.400002    112.0  143.0   83.0     98.0   \n",
      "103160      7       0      36.000000     82.0  167.0   90.0     98.0   \n",
      "\n",
      "        __categorizacion  \n",
      "0                      3  \n",
      "1                      3  \n",
      "2                      2  \n",
      "3                      3  \n",
      "4                      4  \n",
      "...                  ...  \n",
      "103156                 2  \n",
      "103157                 1  \n",
      "103158                 3  \n",
      "103159                 3  \n",
      "103160                 2  \n",
      "\n",
      "[103161 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Codificamos las variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "data['__sexo'] = label_encoder.fit_transform(data['__sexo'])\n",
    "data['__categorizacion'] = label_encoder.fit_transform(data['__categorizacion'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  __sexo  __temperatura  __pulso  __pas  __pad  __sat02  \\\n",
      "0           4       1      36.299999     81.0  129.0   77.0     99.0   \n",
      "1          11       1      36.400002    105.0  185.0   96.0     99.0   \n",
      "2           8       1      36.200001    101.0  129.0   77.0     99.0   \n",
      "3           9       1      36.400002    106.0  125.0   99.0     99.0   \n",
      "4           7       1      36.500000     57.0  118.0   66.0    100.0   \n",
      "...       ...     ...            ...      ...    ...    ...      ...   \n",
      "103156     11       0      36.299999     74.0  152.0   97.0     98.0   \n",
      "103157     10       0      36.500000     60.0  143.0   78.0     98.0   \n",
      "103158      6       1      36.299999     77.0  163.0   77.0    100.0   \n",
      "103159      7       1      36.400002    112.0  143.0   83.0     98.0   \n",
      "103160      7       0      36.000000     82.0  167.0   90.0     98.0   \n",
      "\n",
      "        __categorizacion  \n",
      "0                      3  \n",
      "1                      3  \n",
      "2                      2  \n",
      "3                      3  \n",
      "4                      4  \n",
      "...                  ...  \n",
      "103156                 2  \n",
      "103157                 1  \n",
      "103158                 3  \n",
      "103159                 3  \n",
      "103160                 2  \n",
      "\n",
      "[103161 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Rellenamos los datos faltantes en las demás columnas\n",
    "data = data.fillna(data.median())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  __sexo  __temperatura  __pulso  __pas  __pad  __sat02\n",
      "0           4       1      36.299999     81.0  129.0   77.0     99.0\n",
      "1          11       1      36.400002    105.0  185.0   96.0     99.0\n",
      "2           8       1      36.200001    101.0  129.0   77.0     99.0\n",
      "3           9       1      36.400002    106.0  125.0   99.0     99.0\n",
      "4           7       1      36.500000     57.0  118.0   66.0    100.0\n",
      "...       ...     ...            ...      ...    ...    ...      ...\n",
      "103156     11       0      36.299999     74.0  152.0   97.0     98.0\n",
      "103157     10       0      36.500000     60.0  143.0   78.0     98.0\n",
      "103158      6       1      36.299999     77.0  163.0   77.0    100.0\n",
      "103159      7       1      36.400002    112.0  143.0   83.0     98.0\n",
      "103160      7       0      36.000000     82.0  167.0   90.0     98.0\n",
      "\n",
      "[103161 rows x 7 columns]\n",
      "0         3\n",
      "1         3\n",
      "2         2\n",
      "3         3\n",
      "4         4\n",
      "         ..\n",
      "103156    2\n",
      "103157    1\n",
      "103158    3\n",
      "103159    3\n",
      "103160    2\n",
      "Name: __categorizacion, Length: 103161, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Definimos las características y la variable objetivo\n",
    "x = data.drop(columns=['__categorizacion'])\n",
    "y = data['__categorizacion']\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=200, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo de Random Forest\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Realizamos predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48030631038159555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        76\n",
      "           1       0.30      0.08      0.12      1840\n",
      "           2       0.55      0.30      0.39      5743\n",
      "           3       0.46      0.53      0.49     12009\n",
      "           4       0.49      0.59      0.54     11281\n",
      "\n",
      "    accuracy                           0.48     30949\n",
      "   macro avg       0.36      0.30      0.31     30949\n",
      "weighted avg       0.48      0.48      0.47     30949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos los hiperparámetros en caso de ser necesario para mejorar el rendimiento\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  50.3s[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  48.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  49.5s\n",
      "\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/externals/loky/backend/queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/externals/loky/backend/reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/externals/loky/backend/reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/_memmapping_reducer.py\", line 451, in __call__\n    for dumped_filename in dump(a, filename):\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"/usr/lib/python3.8/pickle.py\", line 487, in dump\n    self.save(obj)\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"/home/ubuntu20/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creamos el modelo de Grid Search\u001b[39;00m\n\u001b[1;32m      2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_search)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mostramos los mejores parámetros\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgrid_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "# Mostramos los mejores parámetros\n",
    "print(grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
